{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science (for complete beginners) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is Data Science?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Depends who you ask:\n",
    "\t* According to my former Statistics lecturer, a Data Scientist is a Statistican under the age of 30\n",
    "\t* If you ask a Data Scientist, they are cowboys on the new Big Data frontier wrestling with the worlds hardest problems\n",
    "\t* Others have said data scientists people who are better at statistics than any software engineer and better at software engineering than any statistician\n",
    "\t* In reality, they are participants in a multidisciplinary field that combines Software Engineering and Statistics with good old fashioned domain knowledge.\n",
    "\n",
    "* What's the difference between Automation and Data Science?\n",
    "\t* Automation is about creating an agent who is able to perform a task, Data Science is about providing new insight into problem domains\n",
    "\n",
    "* What the heck is this Big Data thing anyway?\n",
    "\t* Good question ... next question please!\n",
    "\t* Big Data is phrase that has almost become meaningless, what makes data big?\n",
    "\t* My opinion, if your dataset doesn't fit in the main memory of your machine, your data is big.\n",
    "\t* Worth noting, bigger doesn't always mean better. More important to get a represntative sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Where do I get my data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That depends entirely on what kind of data you wish to work with, and what you're trying to achieve. If you wish to experiment with some of the techniques covered today, or want to play with some new toy from Google (TensorFlow anyone?) then pubically available datasets are a great chance to get to grips with some of these tools. \n",
    "\n",
    "However if you wish to deliver some new insight for you or the business, then you'll need to find/build your own dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Public Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many great resources online with collections of publically available datasets, although some of my personal favourites include: \n",
    "\n",
    "* [Kaggle (the home for all things Data Science)](https://www.kaggle.com/datasets)\n",
    "* [University of California, Irvine Machine Learning repository](http://archive.ics.uci.edu/ml/)\n",
    "* [Quandl](https://www.quandl.com)\n",
    "* [Amazon's AWS Datasets](http://aws.amazon.com/datasets/)\n",
    "* [University of Edinburgh's dataset collection](http://www.inf.ed.ac.uk/teaching/courses/dme/html/datasets0405.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Understanding your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you begin modelling your data there is really two important questions\n",
    "\n",
    "* What kind of task do I want this data to perform with this data (Regression vs Classification vs Clustering)\n",
    "* What kind of learning do I need to in order to achieve that task (Supervised vs Unsupervised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised vs Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When discussing learning methods (we want our algorithms to learn features of our data, in order to create models) we often mention what type of learning we wish to do, these are  categorised into *supervised* and *unsupervised* learning tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised learning is the process of learning by example, similar to a teacher teaching a student. Your training data consists of training examples where we have some feature/predictor variables and a label/target variable.\n",
    "\n",
    "$$\\mathbf{x} = (x_1,x_2,...,x_n)^T$$\n",
    "$$f(\\mathbf{x}) \\rightarrow y  $$\n",
    "\n",
    "An example of a supervised task would be to determine the credit worthiness, using features obtained from their financial history, and we have similar data of customers of customer who may have defaulted in the past. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unsupervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsupervised learning is the opposite, our data is unlabeled in this case, and our algorithms try to find some structure or rules based on the data we provide. \n",
    "\n",
    "One of the most famous examples of an unsupervised machine learning algorithm in the real world would probably be Googles PageRank algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression vs Classification vs Clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "* Classification is probably the most intuitive task, your algorithm will attempt to assign your observations into discrete classes, based on previously observed examples.\n",
    "\n",
    "* An algorithm that implements classifiation is called a **classifier**, and are instances of a supervised learning task.\n",
    "\n",
    "* i.e. We are classifying based on example classes we've seen before, where we have some label determining the correct result. \n",
    "\n",
    "Typical classification tasks include:\n",
    "\n",
    "* Spam or Ham detection for emails\n",
    "* Credit worthyness, would you give this person a loan?\n",
    "* Detecting whether or not a human face is present in the picture\n",
    "\n",
    "* To the board for an Oranges to Lemons example!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "* Where classifiers deal with discrete classifications, regression algorithms deal with continuous response variables. \n",
    "* Remember $y=mx + c$? Then you've used a regression algorithm!\n",
    "* Regression models aim to predict a response variable, given some known variables. \n",
    "* When you're predicting within a range already observed in the dataset, you are *interpolating*\n",
    "* When you're predicting outside of the range of the dataset, you are *extrapolating*\n",
    "\n",
    "Typical regression tasks include:\n",
    "\n",
    "* Predicting the price of the stock market \n",
    "* Calculating life expectancy\n",
    "* I'm sure people in the room have even more examples...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "* Unlike Classification and Regression, Clustering is an unsupervised task\n",
    "* Wish to group similar or related data into some sort of cluster\n",
    "* This can be a hard task to get right, and can be used to achieve different goals\n",
    "* Generally used where getting hold of labelled data is impossible or infeasable! \n",
    "\n",
    "Typical examples include:\n",
    "\n",
    "* Topic modeling, grouping articles together based on underlying \"themes\" of your articles\n",
    "* Forming connected graphs of references between documents to infer relevancy (ever heard of Google?)\n",
    "* Analysis of 'tribe' behaviour in social groups\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever we have a new dataset to work with, it's important to be able to manipulate and play with our new dataset. This helps us get a feel for what our dataset actually is, and allows us to:\n",
    "\n",
    "* Maximise the insight into the dataset and it's main characteristics \n",
    "* Detect mistakes, missing values, outliers and anomalies\n",
    "* Determine relationships between the input variables\n",
    "* Improve the quality of our data and avoid feeding our models with garbage\n",
    "* Determine what algorithms we wish to use to build our models. \n",
    "\n",
    "So with this in mind ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. How do I preprocess my data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When creating statistical models, our models are only as good as the data we provide. This experience is nicely summarised by the expression \"Garbage in, Garbage out\".\n",
    "\n",
    "Therefore it's worth investing time upfront to ensure your data is up to par, saving you headaches (and poor results) in the future. For a Data Scientist, this preprocessing takes up the majority of your time.\n",
    "\n",
    "As a result, there are some common problems that you need to look out for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanced Datasets\n",
    "\n",
    "Imagine you were building a classifier to determine whether a Physicist, who has recently been awarded their PhD, was likely to be awarded a nobel prize in the future. What simple rule would guarantee excellent performance of your classifier?\n",
    "\n",
    "This is why having balanced datasets is important as they can skew the percieved performance of your classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling\n",
    "\n",
    "Below is a table containing the first 5 records from a collection, and we're looking at two columns in particular. Can you spot what may be an issue here?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25</td>\n",
       "      <td>67</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15</td>\n",
       "      <td>54</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17</td>\n",
       "      <td>60</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, iplot\n",
    "from sklearn import preprocessing\n",
    "\n",
    "wineQ = pd.io.parsers.read_csv(\n",
    "    'https://raw.githubusercontent.com/schafer14/Machine-Learning-Wine-DataSets/master/files/winelist.csv',\n",
    "    )\n",
    "header = wineQ.columns.values\n",
    "npArray = np.array(wineQ)\n",
    "X = npArray[:,:-1].astype(float)\n",
    "y = npArray[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Building your models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A combination of task + learning method generally drives the choice of our models. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-Neartest Neighbour (or k-NN for short) is a classifier that tries to to determine the label of the input, based on its relative distance in some multidimensional feature space. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99        88\n",
      "          1       0.99      0.97      0.98        91\n",
      "          2       0.99      0.99      0.99        86\n",
      "          3       0.98      0.87      0.92        91\n",
      "          4       0.99      0.96      0.97        92\n",
      "          5       0.95      0.97      0.96        91\n",
      "          6       0.99      0.99      0.99        91\n",
      "          7       0.96      0.99      0.97        89\n",
      "          8       0.94      1.00      0.97        88\n",
      "          9       0.93      0.98      0.95        92\n",
      "\n",
      "avg / total       0.97      0.97      0.97       899\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[87  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 88  1  0  0  0  0  0  1  1]\n",
      " [ 0  0 85  1  0  0  0  0  0  0]\n",
      " [ 0  0  0 79  0  3  0  4  5  0]\n",
      " [ 0  0  0  0 88  0  0  0  0  4]\n",
      " [ 0  0  0  0  0 88  1  0  0  2]\n",
      " [ 0  1  0  0  0  0 90  0  0  0]\n",
      " [ 0  0  0  0  0  1  0 88  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 88  0]\n",
      " [ 0  0  0  1  0  1  0  0  0 90]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/angusscott/anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "# Author: Gael Varoquaux <gael dot varoquaux at normalesup dot org>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics\n",
    "\n",
    "# The digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# The data that we are interested in is made of 8x8 images of digits, let's\n",
    "# have a look at the first 3 images, stored in the `images` attribute of the\n",
    "# dataset.  If we were working from image files, we could load them using\n",
    "# pylab.imread.  Note that each image must have the same size. For these\n",
    "# images, we know which digit they represent: it is given in the 'target' of\n",
    "# the dataset.\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)\n",
    "\n",
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "# Create a classifier: a support vector classifier\n",
    "classifier = svm.SVC(gamma=0.001)\n",
    "\n",
    "# We learn the digits on the first half of the digits\n",
    "classifier.fit(data[:n_samples / 2], digits.target[:n_samples / 2])\n",
    "\n",
    "# Now predict the value of the digit on the second half:\n",
    "expected = digits.target[n_samples / 2:]\n",
    "predicted = classifier.predict(data[n_samples / 2:])\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "\n",
    "images_and_predictions = list(zip(digits.images[n_samples / 2:], predicted))\n",
    "for index, (image, prediction) in enumerate(images_and_predictions[:4]):\n",
    "    plt.subplot(2, 4, index + 5)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Prediction: %i' % prediction)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees (and Random Forests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluating your models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusions and further reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we have covered:\n",
    "\n",
    "* What Data Science is, and took our first step to becoming world leading Data Scientists\n",
    "* Looked at some popular online data repositories\n",
    "* Discussed the differences between supervised and unsupervised learning\n",
    "* Considered the differences between classification, regression and clustering tasks\n",
    "* Discovered why it's so important to look at our data before we even start to process or model it\n",
    "* The idea of Garbage in, Garbage out\n",
    "* Cleaning and scaling our data, in order to improve the performance of our models\n",
    "* Learnt about three popular models for machine learning: \n",
    "\t* k-Nearest Neighbours\n",
    "\t* Decision Trees\n",
    "\t* Random Forests\n",
    "* Discussed how we should evaluate our models, and why evaluation is so important in the first place. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further watching/listening/reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Watch:\n",
    "\n",
    "Andrew Ng's Stanford course on Machine Learning\n",
    "\n",
    "Listen:\n",
    "\n",
    "Talking Machines\n",
    "Goldmans Sachs episode on Data Science\n",
    "Data Viz\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}